{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data and Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "dataset = pd.read_csv(\"sentiments.tsv\",sep=\"\\t\" ,header=None)\n",
    "dataset.rename(columns = {0:'X',1:'Y'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuation = ['.','?','\"',\"'\",',','-','_','!',':',';','(',')','{','}','[',']','/','#','*','&','$','%','^','@',\n",
    "               '+','-','\\\\','>','<','=','0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "stopword = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', \n",
    "            'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', \n",
    "            'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its',\n",
    "            'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "            'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have',\n",
    "            'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an',\n",
    "            'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n",
    "            'of', 'at', 'by', 'for', 'with', 'about', 'against', 'gonna','between', 'into',\n",
    "            'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up',\n",
    "            'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then',\n",
    "            'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both',\n",
    "            'each', 'few', 'more', 'most', 'other', 'some', 'such', 'nor','only', 'own',\n",
    "            'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will','just', 'don',\n",
    "            'should', 'now', 'd', 'll', 're', 've', 'm','whose']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset['X'])):\n",
    "    s = dataset.loc[i,'X']\n",
    "    for j in punctuation:\n",
    "        s = s.lower()\n",
    "        s = s.replace(j,' ')\n",
    "    dataset.loc[i,'X'] = s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset['X'])):\n",
    "    s = dataset.loc[i,'X']\n",
    "    s = s.split()\n",
    "    l = []\n",
    "    for j in s:\n",
    "        if j not in stopword:\n",
    "            l.append(j)\n",
    "    s = \" \".join(l)\n",
    "    dataset.loc[i,'X'] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slow moving aimless movie distressed drifting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not sure lost flat characters audience nearly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempting artiness black white clever camera ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>little music anything speak</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best scene movie gerardo trying find song keep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>got bored watching jessice lange take clothes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>unfortunately virtue film production work lost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>word embarrassing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>exceptionally bad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>insult one intelligence huge waste money</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     X  Y\n",
       "0    slow moving aimless movie distressed drifting ...  0\n",
       "1    not sure lost flat characters audience nearly ...  0\n",
       "2    attempting artiness black white clever camera ...  0\n",
       "3                          little music anything speak  0\n",
       "4    best scene movie gerardo trying find song keep...  1\n",
       "..                                                 ... ..\n",
       "804      got bored watching jessice lange take clothes  0\n",
       "805  unfortunately virtue film production work lost...  0\n",
       "806                                  word embarrassing  0\n",
       "807                                  exceptionally bad  0\n",
       "808           insult one intelligence huge waste money  0\n",
       "\n",
       "[809 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dataset = []\n",
    "y_dataset = []\n",
    "\n",
    "for i in range(0,len(dataset)):\n",
    "        xt = dataset.loc[i,'X'].split()\n",
    "        x_dataset.append(xt)\n",
    "        y_dataset.append(dataset.loc[i,'Y'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Dataset into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    train_split = 0.8\n",
    "    test_split = 0.2\n",
    "    idx = dataset.index.values.astype(int)\n",
    "    n = len(dataset)\n",
    "\n",
    "    np.random.seed(776)  \n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    xtrain = []\n",
    "    ytrain = []\n",
    "    xtest = []\n",
    "    ytest = []\n",
    "\n",
    "    train_cnt = round(0.8*n)\n",
    "    test_cnt = round(0.2*n)\n",
    "    \n",
    "    for i in range(0,train_cnt):\n",
    "        xtrain.append(x_dataset[idx[i]])\n",
    "        ytrain.append(y_dataset[idx[i]])\n",
    "\n",
    "    for i in range(train_cnt,len(idx)):\n",
    "        xtest.append(x_dataset[idx[i]])\n",
    "        ytest.append(y_dataset[idx[i]])\n",
    "        \n",
    "    return xtrain,ytrain,xtest,ytest \n",
    "\n",
    "x_train,y_train,x_test,y_test = train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Vocabulary on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_set = set()\n",
    "vocabulary = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    l = x_train[i]\n",
    "    for j in l:\n",
    "        vocabulary_set.add(j)\n",
    "        \n",
    "for i in vocabulary_set:\n",
    "    vocabulary.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Prior Probability for each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4652241112828439\n",
      "0.5347758887171561\n"
     ]
    }
   ],
   "source": [
    "zero_class,one_class = 0,0\n",
    "z_cnt,o_cnt = 0,0\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==1:\n",
    "        o_cnt+=1\n",
    "    else:\n",
    "        z_cnt+=1\n",
    "zero_class = z_cnt/len(y_train)\n",
    "one_class = o_cnt/len(y_train)\n",
    "print(zero_class)\n",
    "print(one_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Conditional Probabilities for all Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_class_data = []\n",
    "one_class_data = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    if(y_train[i]==0):\n",
    "        zero_class_data += x_train[i]\n",
    "    else:\n",
    "        one_class_data += x_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_class_dict = {}\n",
    "one_class_dict = {}\n",
    "\n",
    "v_cnt = len(vocabulary)\n",
    "z_cnt = len(zero_class_data)\n",
    "o_cnt = len(one_class_data)\n",
    "\n",
    "for i in range(len(vocabulary)):\n",
    "    word = vocabulary[i]\n",
    "    cnt = 0\n",
    "    for j in range(len(zero_class_data)):\n",
    "        if (word==zero_class_data[j]):\n",
    "            cnt += 1\n",
    "    probability = (cnt+1)/(z_cnt+v_cnt)\n",
    "    zero_class_dict.update({word:probability})\n",
    "\n",
    "for i in range(len(vocabulary)):\n",
    "    word = vocabulary[i]\n",
    "    cnt = 0\n",
    "    for j in range(len(one_class_data)):\n",
    "        if (word==one_class_data[j]):\n",
    "            cnt += 1\n",
    "    probability = (cnt+1)/(o_cnt+v_cnt)\n",
    "    one_class_dict.update({word:probability})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Posterior Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    z_class,o_class,l = 1,1,x_test[i]\n",
    "    for j in range(len(l)):\n",
    "        if l[j] in vocabulary:\n",
    "            z_class *= zero_class_dict[l[j]]\n",
    "            o_class *= one_class_dict[l[j]]\n",
    "        else:\n",
    "            z_class *= 1/(z_cnt+v_cnt)\n",
    "            o_class *= 1/(o_cnt+v_cnt)\n",
    "            \n",
    "    z_class *= zero_class\n",
    "    o_class *= one_class\n",
    "    \n",
    "    if(z_class>o_class):\n",
    "        y_predict.append(0)\n",
    "    else:\n",
    "        y_predict.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 87.03703703703704\n",
      "Precision 83.75\n",
      "Recall 89.33333333333333\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix():\n",
    "    TP,TN,FP,FN = 0,0,0,0\n",
    "    for i in range(len(y_test)):\n",
    "        if(y_predict[i]==1 and y_test[i]==1):\n",
    "            TP += 1\n",
    "        elif(y_predict[i]==1 and y_test[i]==0):\n",
    "            FP += 1\n",
    "        elif(y_predict[i]==0 and y_test[i]==1):\n",
    "            FN += 1\n",
    "        elif(y_predict[i]==0 and y_test[i]==0):\n",
    "            TN += 1\n",
    "    accuracy = ((TP+TN)/(TP+TN+FP+FN))*100\n",
    "    precision = (TP/(TP+FP))*100\n",
    "    recall = (TP/(TP+FN))*100\n",
    "    print(\"Accuracy \"+str(accuracy))\n",
    "    print(\"Precision \"+str(precision))\n",
    "    print(\"Recall \"+str(recall))\n",
    "    \n",
    "confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
